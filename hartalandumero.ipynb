{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "import selenium.webdriver.common.keys\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ChromeDriver executable and start a Chrome browser using Selenium\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the webpage\n",
    "driver.get('https://merolagani.com/Floorsheet.aspx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract data from the current page\n",
    "def extract_page_data():\n",
    "    # Let's use BeautifulSoup to parse the page source\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract the data you need from the current page\n",
    "    # Adjust the selectors based on your HTML structure\n",
    "    data = []\n",
    "    rows = soup.select('.table-bordered tbody tr')\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        row_data = [column.get_text(strip=True) for column in columns]\n",
    "        data.append(row_data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the \"Items per page\" filter is a dropdown with the class 'ng-untouched'\n",
    "# Wait for the dropdown to be present on the page\n",
    "#wait = WebDriverWait(driver, 10)\n",
    "#items_per_page_dropdown = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ng-untouched')))\n",
    "#items_per_page_dropdown.click()\n",
    "# Find the option with value '500' and click on it\n",
    "#option_500 = wait.until(EC.element_to_be_clickable((By.XPATH, '//option[@value=\"500\"]')))\n",
    "#option_500.click()\n",
    "#filter_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'box__filter--search')))\n",
    "#filter_button.click()\n",
    "#print(driver.page_source)\n",
    "#driver.implicitly_wait(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the input element by its ID\n",
    "input_element = driver.find_element(By.ID, 'ctl00_ContentPlaceHolder1_txtFloorsheetDateFilter')\n",
    "#input_element = driver.find_element_by_id('ctl00_ContentPlaceHolder1_txtFloorsheetDateFilter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the input element by its ID\n",
    "#input_element = driver.find_element_by_id('ctl00_ContentPlaceHolder1_txtFloorsheetDateFilter')\n",
    "\n",
    "# Enter a new date\n",
    "new_date = '01/18/2024'\n",
    "input_element.send_keys(new_date)\n",
    "\n",
    "# Find the span element by its ID\n",
    "date_span = driver.find_element(By.ID, 'ctl00_ContentPlaceHolder1_marketDate')\n",
    "# Extract the text value from the span element\n",
    "date_value = date_span.text\n",
    "# Print the extracted value\n",
    "#print(\"Date Value:\", date_value)\n",
    "# Press Enter to confirm the new date (optional, depends on the website's behavior)\n",
    "input_element.send_keys(Keys.ENTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the element to be clickable (you might need to adjust the timeout)\n",
    "search_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID, 'ctl00_ContentPlaceHolder1_lbtnSearchFloorsheet'))\n",
    ")\n",
    "# Click the \"Search\" button\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the specific date (e.g., start from one week ago)\n",
    "start_date_str = '01/18/2024'\n",
    "start_date = datetime.strptime(specific_date_str, '%m/%d/%Y')\n",
    "\n",
    "# Get the current date\n",
    "end_date = datetime.now()\n",
    "\n",
    "# Iterate through the date range\n",
    "while start_date <= end_date:\n",
    "    # Format the current date as MM/DD/YYYY and print\n",
    "    current_date_str = start_date.strftime('%m/%d/%Y')\n",
    "    date_input.clear()\n",
    "    date_input.send.keys(current_date_str)\n",
    "    print(current_date_str)\n",
    "\n",
    "    # Move to the next date\n",
    "    start_date += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to click the next page button\n",
    "def click_next_page():\n",
    "    try:\n",
    "        # Find the next page element and click it\n",
    "        next_page = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[text()=\"Next\"]'))\n",
    "        )\n",
    "        next_page.click()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking next page: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data from all pages\n",
    "all_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# Set the number of pages you want to scrape\n",
    "span_element = soup.find('span', id='ctl00_ContentPlaceHolder1_PagerControl1_litRecords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the total pages value from the content\n",
    "#total_pages_text = span_element.get_text(strip=True)\n",
    "#start_index = total_pages_text.find(\"[Total pages:\") + len(\"[Total pages:\")\n",
    "#end_index = total_pages_text.find(\"]\", start_index)\n",
    "\n",
    "#total_pages_value = total_pages_text[start_index:end_index]\n",
    "#num_pages_to_scrape = int(total_pages_value)\n",
    "\n",
    "#testing number of pages:\n",
    "num_pages_to_scrape = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through pages\n",
    "for page_num in range(num_pages_to_scrape):\n",
    "    print(f\"Scraping data from page {page_num + 1}\")\n",
    "\n",
    "    # Extract data from the current page\n",
    "    current_data = extract_page_data()\n",
    "    all_data.extend(current_data)\n",
    "\n",
    "    # Click the next page\n",
    "    if not click_next_page():\n",
    "        print(\"No more pages to scrape.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the collected data\n",
    "print(\"Collected Data:\")\n",
    "for row in all_data:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
